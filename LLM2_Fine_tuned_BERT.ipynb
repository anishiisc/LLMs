{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4cefc60069a04b6d9d6898aed74594d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b318346c9b240349451b0719b968049",
              "IPY_MODEL_37be93909f79498588c71df0967da53a",
              "IPY_MODEL_1530564fb4ed43f48eb84cfa33b78ca4"
            ],
            "layout": "IPY_MODEL_e7b7b35c7ae04442bce2ba33a6295c3e"
          }
        },
        "2b318346c9b240349451b0719b968049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e8bab5949f24b33a05a5783e2a0817a",
            "placeholder": "​",
            "style": "IPY_MODEL_b36c5af762024a9aa67a5f101b5bddd1",
            "value": "model.safetensors: 100%"
          }
        },
        "37be93909f79498588c71df0967da53a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b586f85b939b487dab836a46597f98a4",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74be9e0176a841af9fe55b708dd16302",
            "value": 440449768
          }
        },
        "1530564fb4ed43f48eb84cfa33b78ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7388bafa53ec4e32995003ab176a7ff4",
            "placeholder": "​",
            "style": "IPY_MODEL_e88a260f2d9a4accac4cc02d7e915b34",
            "value": " 440M/440M [00:05&lt;00:00, 116MB/s]"
          }
        },
        "e7b7b35c7ae04442bce2ba33a6295c3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e8bab5949f24b33a05a5783e2a0817a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b36c5af762024a9aa67a5f101b5bddd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b586f85b939b487dab836a46597f98a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74be9e0176a841af9fe55b708dd16302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7388bafa53ec4e32995003ab176a7ff4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e88a260f2d9a4accac4cc02d7e915b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## LLM Fine Tuning on SquAD format  JSON with data on Beyonce\n",
        "\n",
        "REF https://stackabuse.com/guide-to-fine-tuning-open-source-llms-on-custom-data\n",
        "\n"
      ],
      "metadata": {
        "id": "g_sNF9AdUskf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "z5uEf70AUr5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and import the modules\n",
        "!pip install torch\n",
        "!pip install transformers\n",
        "\n",
        "import json\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForQuestionAnswering\n",
        "from torch.utils.data import DataLoader, Dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaxczSwXWJ1F",
        "outputId": "59246673-6b0e-448a-f2ac-f24633494e90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Input file path\n",
        "file_path = 'drive/MyDrive/LLM_data/beyonce.json'"
      ],
      "metadata": {
        "id": "zvQgRpjOnGTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stand Alone code for JSON file read and data extract\n",
        ":"
      ],
      "metadata": {
        "id": "erPJODH2oI-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the Json file\n",
        "with open(file_path, 'r') as f:\n",
        "     data = json.load(f)\n",
        "\n",
        "# get the data\n",
        "paragraphs = data['data'][0]['paragraphs']\n",
        "\n",
        "# loop through all the paragraphs\n",
        "# for each para extract the following and create a dict\n",
        "#  1) context  under that context under qas - loop thru to get 2) question 3) answer 4) start pos\n",
        "\n",
        "extracted_data = [ ]\n",
        "for para in paragraphs:\n",
        "    context = para['context']\n",
        "    for qa in para['qas']:\n",
        "        question = qa['question']\n",
        "        answer = qa['answers'][0]['text']\n",
        "        start_pos = qa['answers'][0]['answer_start']\n",
        "    extracted_data.append({\n",
        "                    'context': context,\n",
        "                    'question': question,\n",
        "                    'answer': answer,\n",
        "                    'start_pos': start_pos,\n",
        "                })\n",
        "# data creation ends\n",
        "\n",
        "# check\n",
        "extracted_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-5z-Kz4nSBs",
        "outputId": "bffdbdd5-4b6e-4d36-a86a-f6e536789703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
              " 'question': \"What was the name of Beyoncé's first solo album?\",\n",
              " 'answer': 'Dangerously in Love',\n",
              " 'start_pos': 505}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check number of data points in extracted data\n",
        "len(extracted_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpRjlIYKvWjo",
        "outputId": "53cf8c5f-94dd-494c-835e-8304028a1c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check tokenize separately\n",
        "\n"
      ],
      "metadata": {
        "id": "O4W8suror47Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Set index\n",
        "index = 5\n",
        "\n",
        "# Display data at Set index pos.\n",
        "Example = extracted_data[index]\n",
        "\n",
        "# get the context\n",
        "context = (Example['context'])\n",
        "print(Example['context'])\n",
        "\n",
        "# get the question\n",
        "print(Example['question'])\n",
        "question = Example['question']\n",
        "\n",
        "# get the answer\n",
        "print(Example['answer'])\n",
        "answer = Example['answer']\n",
        "\n",
        "# get the startpos\n",
        "print(Example['start_pos'])\n",
        "startpos = Example['start_pos']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-wLs4fTr-ay",
        "outputId": "4b261914-6471-4d3f-c11a-3684c377440e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At age eight, Beyoncé and childhood friend Kelly Rowland met LaTavia Roberson while in an audition for an all-girl entertainment group. They were placed into a group with three other girls as Girl's Tyme, and rapped and danced on the talent show circuit in Houston. After seeing the group, R&B producer Arne Frager brought them to his Northern California studio and placed them in Star Search, the largest talent show on national TV at the time. Girl's Tyme failed to win, and Beyoncé later said the song they performed was not good. In 1995 Beyoncé's father resigned from his job to manage the group. The move reduced Beyoncé's family's income by half, and her parents were forced to move into separated apartments. Mathew cut the original line-up to four and the group continued performing as an opening act for other established R&B girl groups. The girls auditioned before record labels and were finally signed to Elektra Records, moving to Atlanta Records briefly to work on their first recording, only to be cut by the company. This put further strain on the family, and Beyoncé's parents separated. On October 5, 1995, Dwayne Wiggins's Grass Roots Entertainment signed the group. In 1996, the girls began recording their debut album under an agreement with Sony Music, the Knowles family reunited, and shortly after, the group got a contract with Columbia Records.\n",
            "Who signed the girl group on October 5, 1995?\n",
            "Dwayne Wiggins's Grass Roots Entertainment\n",
            "1126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation of Tokenizer\n",
        "\n",
        "# Reference : https://www.analyticsvidhya.com/blog/2021/09/an-explanatory-guide-to-bert-tokenizer/\n",
        "\n",
        "\n",
        "We will encode a sample question and comtext with the Tokenizer\n",
        "\n",
        "**Question**\n",
        "q1 = 'Who was Tony Stark?'\n",
        "\n",
        "**Context**\n",
        "c1 = 'Anthony Edward Stark known as Tony Stark is a fictional character in Avengers'\n",
        "\n",
        "\n",
        "encoding = tokenizer.encode_plus( q1, c1)\n",
        "\n",
        "## What does encoder_plus do ?\n",
        "\n",
        "- It returns a token for the text - in this case the question and context are clubbed\n",
        "\n",
        "- the token type ids: 0 for first sentence ; 1 for second sentence\n",
        "\n",
        "- Attention mask ; if 1 focus attention on that token\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qw9KO_1GUD7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Example\n",
        "\n",
        "# question\n",
        "q1 = 'Who was Tony Stark?'\n",
        "\n",
        "# context\n",
        "c1 = 'Anthony Edward Stark known as Tony Stark is a fictional character in Avengers'\n",
        "\n",
        "\n",
        "# encoding\n",
        "encoding = tokenizer.encode_plus( q1, c1)\n",
        "\n",
        "\n",
        "# print encoding\n",
        "for key, value in encoding.items():\n",
        "    print( '{} : {}'.format( key, value ) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfQTFrVUROKr",
        "outputId": "4e779cd8-402c-4a42-a256-b2a380eb50d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids : [101, 2040, 2001, 4116, 9762, 1029, 102, 4938, 3487, 9762, 2124, 2004, 4116, 9762, 2003, 1037, 7214, 2839, 1999, 14936, 102]\n",
            "token_type_ids : [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "attention_mask : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now let us try the same on our data for any one index"
      ],
      "metadata": {
        "id": "SzTBOFIfcqUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## call tokenizer on one index pos of the data\n",
        "inputs = tokenizer.encode_plus(question, context, add_special_tokens=True, padding='max_length', max_length=512, truncation=True, return_tensors='pt')\n",
        "\n",
        "\n",
        "# print and display\n",
        "for key, value in inputs.items():\n",
        "    print( '{} : {}'.format( key, value ) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_cnVMkDQOrI",
        "outputId": "383220a8-e020-4343-ced9-3c2708267f4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids : tensor([[  101,  2040,  2772,  1996,  2611,  2177,  2006,  2255,  1019,  1010,\n",
            "          2786,  1029,   102,  2012,  2287,  2809,  1010, 20773,  1998,  5593,\n",
            "          2767,  5163, 20539,  2777,  2474,  2696,  9035, 11111, 17753,  2096,\n",
            "          1999,  2019, 14597,  2005,  2019,  2035,  1011,  2611,  4024,  2177,\n",
            "          1012,  2027,  2020,  2872,  2046,  1037,  2177,  2007,  2093,  2060,\n",
            "          3057,  2004,  2611,  1005,  1055,  5939,  4168,  1010,  1998,  9680,\n",
            "          5669,  1998, 10948,  2006,  1996,  5848,  2265,  4984,  1999,  5395,\n",
            "          1012,  2044,  3773,  1996,  2177,  1010,  1054,  1004,  1038,  3135,\n",
            "         12098,  2638, 25312,  4590,  2716,  2068,  2000,  2010,  2642,  2662,\n",
            "          2996,  1998,  2872,  2068,  1999,  2732,  3945,  1010,  1996,  2922,\n",
            "          5848,  2265,  2006,  2120,  2694,  2012,  1996,  2051,  1012,  2611,\n",
            "          1005,  1055,  5939,  4168,  3478,  2000,  2663,  1010,  1998, 20773,\n",
            "          2101,  2056,  1996,  2299,  2027,  2864,  2001,  2025,  2204,  1012,\n",
            "          1999,  2786, 20773,  1005,  1055,  2269,  5295,  2013,  2010,  3105,\n",
            "          2000,  6133,  1996,  2177,  1012,  1996,  2693,  4359, 20773,  1005,\n",
            "          1055,  2155,  1005,  1055,  3318,  2011,  2431,  1010,  1998,  2014,\n",
            "          3008,  2020,  3140,  2000,  2693,  2046,  5459,  9620,  1012, 25436,\n",
            "          3013,  1996,  2434,  2240,  1011,  2039,  2000,  2176,  1998,  1996,\n",
            "          2177,  2506,  4488,  2004,  2019,  3098,  2552,  2005,  2060,  2511,\n",
            "          1054,  1004,  1038,  2611,  2967,  1012,  1996,  3057, 23008,  2077,\n",
            "          2501, 10873,  1998,  2020,  2633,  2772,  2000,  3449,  5937,  6494,\n",
            "          2636,  1010,  3048,  2000,  5865,  2636,  4780,  2000,  2147,  2006,\n",
            "          2037,  2034,  3405,  1010,  2069,  2000,  2022,  3013,  2011,  1996,\n",
            "          2194,  1012,  2023,  2404,  2582, 10178,  2006,  1996,  2155,  1010,\n",
            "          1998, 20773,  1005,  1055,  3008,  5459,  1012,  2006,  2255,  1019,\n",
            "          1010,  2786,  1010,  1040,  4576,  2638, 24405, 16529,  1005,  1055,\n",
            "          5568,  6147,  4024,  2772,  1996,  2177,  1012,  1999,  2727,  1010,\n",
            "          1996,  3057,  2211,  3405,  2037,  2834,  2201,  2104,  2019,  3820,\n",
            "          2007,  8412,  2189,  1010,  1996, 22815,  2155, 11653,  1010,  1998,\n",
            "          3859,  2044,  1010,  1996,  2177,  2288,  1037,  3206,  2007,  3996,\n",
            "          2636,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0]])\n",
            "token_type_ids : tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "attention_mask : tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post process tokenizer output\n",
        "\n",
        "from Tokenizer  we get output as tensor -\n",
        "\n",
        "We use .squeeze() method to remove single dimension entries\n",
        "\n",
        "**Example is shown below**"
      ],
      "metadata": {
        "id": "EomKMSUKd83M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as geek\n",
        "\n",
        "in_arr = geek.array([[[2, 2, 2], [2, 2, 2]]])\n",
        "\n",
        "print (\"Input array : \", in_arr)\n",
        "print(\"Shape of input array : \", in_arr.shape)\n",
        "\n",
        "out_arr = geek.squeeze(in_arr)\n",
        "\n",
        "print (\"output squeezed array : \", out_arr)\n",
        "print(\"Shape of output array : \", out_arr.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxRNl2hjeG9n",
        "outputId": "cfab0c81-7a09-4a94-aacd-b8e358270067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input array :  [[[2 2 2]\n",
            "  [2 2 2]]]\n",
            "Shape of input array :  (1, 2, 3)\n",
            "output squeezed array :  [[2 2 2]\n",
            " [2 2 2]]\n",
            "Shape of output array :  (2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now Create a Class for the same\n",
        "\n",
        "**Note** We are going to inherit - Dataset class from pytorch\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "\n",
        "\n",
        "To create a custom 'Dataset' class we would need the following methods\n",
        "- __init__\n",
        "- --_len--\n",
        "- --get_item__\n",
        "\n",
        "\n",
        "## Init\n",
        "\n",
        "- In the init class - which will be called when and instance is initiated\n",
        "We are passing the input file path and calling a custom json read method to\n",
        "finally extract the relevant context query answers and start pos in a Dict format .\n",
        "\n",
        "- The dict format is then our returned \"data\"\n",
        "\n",
        "\n",
        "## len\n",
        "Here we just code a return for the length of our 'data'\n",
        "\n",
        "\n",
        "## get item\n",
        "Here we pass the index value to the extracted data and get teh relevant components returned\n"
      ],
      "metadata": {
        "id": "hvuDAE6dhjTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class beyonce(Dataset):\n",
        "    def __init__(self, file_path):\n",
        "        self.data = self.load_data(file_path)\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    def load_data(self, file_path):\n",
        "        with open(file_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "        paragraphs = data['data'][0]['paragraphs']\n",
        "        extracted_data = []\n",
        "        for paragraph in paragraphs:\n",
        "            context = paragraph['context']\n",
        "            for qa in paragraph['qas']:\n",
        "                question = qa['question']\n",
        "                answer = qa['answers'][0]['text']\n",
        "                start_pos = qa['answers'][0]['answer_start']\n",
        "                extracted_data.append({\n",
        "                    'context': context,\n",
        "                    'question': question,\n",
        "                    'answer': answer,\n",
        "                    'start_pos': start_pos,\n",
        "                })\n",
        "        return extracted_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        example = self.data[index]\n",
        "        question = example['question']\n",
        "        context = example['context']\n",
        "        answer = example['answer']\n",
        "        inputs = self.tokenizer.encode_plus(question, context, add_special_tokens=True, padding='max_length', max_length=512, truncation=True, return_tensors='pt')\n",
        "        input_ids = inputs['input_ids'].squeeze()\n",
        "        attention_mask = inputs['attention_mask'].squeeze()\n",
        "        start_pos = torch.tensor(example['start_pos'])\n",
        "        return input_ids, attention_mask, start_pos"
      ],
      "metadata": {
        "id": "hq5PLvzdhiIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loader concepts\n",
        "\n",
        "REF\n",
        "\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "\n",
        "\n",
        "\n",
        "The Dataset retrieves our dataset’s features and labels one sample at a time. While training a model, we typically want to pass samples in “minibatches”, reshuffle the data at every epoch to reduce model overfitting, and use Python’s multiprocessing to speed up data retrieval.\n",
        "\n",
        "DataLoader is an iterable that abstracts this complexity for us in an easy API.\n",
        "\n",
        "\n",
        "## Iterate through the DataLoader\n",
        "\n",
        "We have loaded that dataset into the DataLoader and can iterate through the dataset as needed. Each iteration below returns a batch of train_features  (containing batch_size features ). Because we specified shuffle=True, after we iterate over all batches the data is shuffled (for finer-grained control over the data loading order, take a look at Samplers).\n"
      ],
      "metadata": {
        "id": "uTpTa_WliiTO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create an instance of the beyonce class"
      ],
      "metadata": {
        "id": "t9fLGWkCwMA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'drive/MyDrive/LLM_data/beyonce.json'\n",
        "dataset = beyonce(file_path)"
      ],
      "metadata": {
        "id": "-YFjH2GZihie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up the model for training\n",
        "\n",
        "\n",
        "**We are using the following here**\n",
        "\n",
        "- Adam optimizer and cross entropy loss function.\n",
        "\n",
        "- Pytorch class DataLoader to load data in different batches and also shuffle them to avoid any bias.\n",
        "\n",
        "\n",
        "**Notes**\n",
        "\n",
        "We are using the BERT model specific for Question Answering\n",
        "\n",
        "REF\n",
        "https://huggingface.co/learn/nlp-course/chapter7/7?fw=pt\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kAvi6uksmSsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device (CPU or GPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize the BERT model for question answering\n",
        "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "batch_size = 8\n",
        "num_epochs = 50\n",
        "\n",
        "# Create data loader\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "4cefc60069a04b6d9d6898aed74594d3",
            "2b318346c9b240349451b0719b968049",
            "37be93909f79498588c71df0967da53a",
            "1530564fb4ed43f48eb84cfa33b78ca4",
            "e7b7b35c7ae04442bce2ba33a6295c3e",
            "0e8bab5949f24b33a05a5783e2a0817a",
            "b36c5af762024a9aa67a5f101b5bddd1",
            "b586f85b939b487dab836a46597f98a4",
            "74be9e0176a841af9fe55b708dd16302",
            "7388bafa53ec4e32995003ab176a7ff4",
            "e88a260f2d9a4accac4cc02d7e915b34"
          ]
        },
        "id": "6MRBfb7fmYwu",
        "outputId": "1ffd9e10-635d-47a4-8ff6-15d3bd7e217d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cefc60069a04b6d9d6898aed74594d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in data_loader:\n",
        "        # Move batch tensors to the device\n",
        "        input_ids = batch[0].to(device)\n",
        "        attention_mask = batch[1].to(device)\n",
        "        start_positions = batch[2].to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Average Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "id": "hB4jQ-gL7bS5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MIgO6Rb1mCG8"
      }
    }
  ]
}